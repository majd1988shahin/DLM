# -*- coding: utf-8 -*-
"""Funktional.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1nDgKoHiJZPTXhP5EePAn9a186OevHQJe
"""

from keras.datasets import mnist
from matplotlib import pyplot as plt
import numpy as np

(x_train, y_train), (x_test, y_test) =mnist.load_data()
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
y_test

flat_input_train = np.reshape(x_train,(len(x_train),-1))
print(flat_input_train.shape)
flat_input_test=np.reshape(x_test,(len(x_test),-1))

average_image = np.reshape(np.array([x_train[:,x,y].mean() 
    for x in range(0,28) for y in range(0,28)]),(28,28))

for i in range(0,10):
    
    img = x_train[np.where(y_train==i)[0][0] ,:,:]#erses Bilde von Klasse i ist 
    img_average = img -average_image
        
    # get some image
    plt.figure(i)
    plt.imshow(img_average,cmap="gray")

    plt.figure(i+100)
    plt.hist(img_average.flatten())
    plt.figure(i+200) 
    plt.hist(img.flatten())

flat_input_train_minus_averaged=flat_input_train-img_average.flatten()
flat_input_test_minus_averaged=flat_input_test-img_average.flatten()

from keras.utils import to_categorical

y_train_cat=to_categorical(y_train)
y_test_cat=to_categorical(y_test)

plt.imshow(x_test[18,:,:])

from keras.layers import Input, Dense
from keras.models import Model
from keras.layers import Input, Embedding, LSTM, Dense

def create_model():
    inputs = Input(shape=(flat_input_train.shape[1],))
    #inputs = Input((784,))
# a layer instance is callable on a tensor, and returns a tensor

    x = Dense(32, activation='relu')(inputs)
   # inputs=Input(shape=(32,))
    x = Dense(64, activation='relu')(x)
    

   # x = Dense(4, activation='hard_sigmoid')(x)
   # x = Dense(10, activation='hard_sigmoid')(x)

    predictions = Dense(10, activation='softmax')(x)

# This creates a model that includes
# the Input layer and three Dense layers
    model = Model(inputs=inputs, outputs=predictions)
    model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
    #model.add(Dense(32, input_dim=flat_input_train.shape[1]))
    
    #model.add(Dense(64,activation="relu"))
    
    # Final layer - choose the amount of classes
    #model.add(Dense(10,activation="softmax"))
    return model

optimizer = "adadelta"

   # print("optimizers_to_test :" ,optimizer)
model = create_model()
    
model.compile(optimizer=optimizer,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
hist = model.fit(flat_input_train,y_train_cat,validation_data=\
              (flat_input_test,y_test_cat),epochs=1)
    
plt.figure(999)
plt.plot(hist.history["loss"])
plt.title("Training Loss")
   
plt.figure(998)
plt.plot(hist.history["val_loss"])
plt.title("Validation Loss")
    
plt.figure(888)
plt.plot(hist.history["acc"])
plt.title("Trainings Accuracy")
    
plt.figure(887)
plt.plot(hist.history["val_acc"])
plt.title("Validation Accuracy")
y=model.predict(flat_input_test)
print(model.summary())

model.summary()

"""InputLayer ist bei sequential nicht stattgefunden !"""

i=737

x1=[list(y[i,:]).index(max(list(y[i,:]))) for i in range(0,10000) ]
print(*zip(y_test,x1))
print(y_test[i],y[i])
print(sum(x1==y_test))

"""# Merge Layer"""

input1= Input(shape=(16,))
x=Dense(8,activation="relu")(input1)

from keras.layers import Concatenate
concated=Concatenate()([x,input1])
out =Dense(1,activation="linear")(concated)
model2=Model(inputs=input1, outputs=out)
model2.compile("adam","mean_squared_error", metrics=['accuracy'])

np.random.seed(15)
X=np.random.randint(0,100,size=(100,16))
Y=[np.mean(X[i,:]) for i in range(0,100)]
model2.fit(X,Y,epochs=100)

np.mean(abs(model2.predict(X)-Y))



"""# Aufgabe4"""

from keras.layers import Concatenate

inputs = Input(name="inputs",shape=(flat_input_train.shape[1],))
x1=Dense(64,activation="relu",name="x1")(inputs)
x2=Dense(64,activation="relu",name="x2")(x1)
concatenate1=Concatenate(name="concatenate1")([x1,x2])
x3=Dense(64,activation="relu",name="x3")(concatenate1)
concatenate2=Concatenate(name="concatenate2")([x3,x1])
outputs=Dense(10,activation="softmax",name="output")(concatenate2)

model3=Model(inputs=inputs,outputs=outputs)
model3.summary()

model3.compile("adamax",loss='categorical_crossentropy',
                  metrics=['accuracy'])

np.random.seed(9)
model3.fit(flat_input_train,y_train_cat,
           validation_data=(flat_input_test,y_test_cat),epochs=15)

import os , sys
from google.colab import drive
drive.mount('/content/drive') #get access to drive

os.chdir("/content/drive/My Drive/PYP") # change working directory
print(os.getcwd())# read current work direktory
#model3.save("Aufgabe4.hdf5")

j=model3.to_json();
with open("A4.json","+w") as f:
  f.write(j)

!ls

"""# Dropout !"""

from keras.layers import Dropout
inputs = Input(name="inputs",shape=(flat_input_train.shape[1],))
x1=Dense(64,activation="relu",name="x1")(inputs)
dropout=Dropout(0.2, noise_shape=None, seed=None)(x1)

x2=Dense(64,activation="relu",name="x2")(dropout)
concatenate1=Concatenate(name="concatenate1")([dropout,x2])
x3=Dense(64,activation="relu",name="x3")(concatenate1)
concatenate2=Concatenate(name="concatenate2")([x3,dropout])
outputs=Dense(10,activation="softmax",name="output")(concatenate2)

model4=Model(inputs=inputs,outputs=outputs)
model4.summary()



model3.compile("adamax",loss='categorical_crossentropy',
                  metrics=['accuracy'])

np.random.seed(9)
model3.fit(flat_input_train,y_train_cat,
           validation_data=(flat_input_test,y_test_cat),epochs=25)
